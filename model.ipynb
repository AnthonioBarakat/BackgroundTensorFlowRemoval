{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Concatenate, UpSampling2D, \\\n",
    "                                    BatchNormalization, Activation\n",
    "from tensorflow.keras.models import Model\n",
    "import cv2\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_image(file_path):\n",
    "    image = cv2.imread(file_path)\n",
    "    image = cv2.resize(image, (64, 64))\n",
    "    image_array = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    return image_array\n",
    "\n",
    "def read_mask(file_path):\n",
    "    mask = cv2.imread(file_path, cv2.IMREAD_GRAYSCALE)\n",
    "    mask = cv2.resize(mask, (64, 64))\n",
    "    return mask\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = 'ds/people_segmentation'\n",
    "images_file_paths = glob(data_dir + '/images/*.jpg')\n",
    "masks_file_paths = glob(data_dir + '/masks/*.png')\n",
    "# dataset = file_paths.map(load_image_and_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = []\n",
    "for image_path in images_file_paths:\n",
    "  images.append(read_image(image_path))\n",
    "images = np.array([images])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "masks = []\n",
    "for mask_path in masks_file_paths:\n",
    "  masks.append(read_mask(mask_path))\n",
    "masks = np.array([masks])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = images.reshape(images[0].shape)\n",
    "masks = masks.reshape(masks[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5678, 64, 64, 3)\n",
      "(5678, 64, 64)\n"
     ]
    }
   ],
   "source": [
    "print(images.shape)\n",
    "print(masks.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x, test_x = train_test_split(images, test_size=0.1, random_state=42)\n",
    "train_y, test_y = train_test_split(masks, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def residual_block(inputs, filters_count):\n",
    "  x_skip = Conv2D(filters_count, 1, padding = 'same')(inputs)\n",
    "  x_skip = BatchNormalization()(x_skip)\n",
    "\n",
    "  x = Conv2D(filters_count, 3, padding = 'same')(inputs)\n",
    "  x = BatchNormalization()(x)\n",
    "  x = Activation('relu')(x)\n",
    "\n",
    "  x = Conv2D(filters_count, 4, padding = 'same')(x)\n",
    "  x = BatchNormalization()(x)\n",
    "\n",
    "  x = Activation('relu')(x + x_skip)\n",
    "\n",
    "  return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def inception_conv_block(inputs, filters_count):\n",
    "#   x1 = Conv2D(filters_count, 3, padding = \"same\", dilation_rate=3)(inputs)\n",
    "#   x1 = BatchNormalization()(x1)\n",
    "#   x1 = Activation('relu')(x1)\n",
    "\n",
    "#   x2 = Conv2D(filters_count, 3, padding = \"same\", dilation_rate=6)(inputs)\n",
    "#   x2 = BatchNormalization()(x2)\n",
    "#   x2 = Activation('relu')(x2)\n",
    "\n",
    "#   x3 = Conv2D(filters_count, 3, padding = \"same\", dilation_rate=9)(inputs)\n",
    "#   x3 = BatchNormalization()(x3)\n",
    "#   x3 = Activation('relu')(x3)\n",
    "\n",
    "#   x_concat = Concatenate([x1, x2, x3])\n",
    "#   x_concat = Conv2D(filters_count, 1, padding = \"same\")(x_concat)\n",
    "#   x_concat = BatchNormalization()(x_concat)\n",
    "#   x_concat = Activation('relu')(x_concat)\n",
    "\n",
    "#   return x_concat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def u_model(input_shape):\n",
    "    inputs = Input(input_shape)\n",
    "    \n",
    "    # Encoder\n",
    "    conv1 = Conv2D(64, 3, activation='relu', padding='same')(inputs)\n",
    "    conv1 = Conv2D(64, 3, activation='relu', padding='same')(conv1)\n",
    "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "\n",
    "    conv2 = Conv2D(128, 3, activation='relu', padding='same')(pool1)\n",
    "    conv2 = Conv2D(128, 3, activation='relu', padding='same')(conv2)\n",
    "    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "\n",
    "    ##\n",
    "    conv3 = residual_block(pool2, 256)\n",
    "    # conv3 = inception_conv_block(conv3, 256)\n",
    "    conv3 = Conv2D(256, 3, activation='relu', padding='same')(conv3)\n",
    "    conv3 = Conv2D(256, 3, activation='relu', padding='same')(conv3)\n",
    "\n",
    "    # Decoder\n",
    "    up4 = UpSampling2D(size=(2, 2))(conv3)\n",
    "    up4 = Conv2D(128, 2, activation='relu', padding='same')(up4)\n",
    "    merge4 = Concatenate()([conv2, up4])\n",
    "    conv4 = Conv2D(128, 3, activation='relu', padding='same')(merge4)\n",
    "    conv4 = Conv2D(128, 3, activation='relu', padding='same')(conv4)\n",
    "\n",
    "    up5 = UpSampling2D(size=(2, 2))(conv4)\n",
    "    up5 = Conv2D(64, 2, activation='relu', padding='same')(up5)\n",
    "    merge5 = Concatenate()([conv1, up5])\n",
    "    conv5 = Conv2D(64, 3, activation='relu', padding='same')(merge5)\n",
    "    conv5 = Conv2D(64, 3, activation='relu', padding='same')(conv5)\n",
    "\n",
    "    # Output layer\n",
    "    outputs = Conv2D(1, 1, activation='sigmoid')(conv5)\n",
    "\n",
    "    model = Model(inputs=inputs, outputs=outputs)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = u_model((64, 64, 3))\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4), \n",
    "              loss='binary_crossentropy', \n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_5 (InputLayer)            [(None, 64, 64, 3)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_50 (Conv2D)              (None, 64, 64, 64)   1792        input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_51 (Conv2D)              (None, 64, 64, 64)   36928       conv2d_50[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2D)  (None, 32, 32, 64)   0           conv2d_51[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_52 (Conv2D)              (None, 32, 32, 128)  73856       max_pooling2d_8[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_53 (Conv2D)              (None, 32, 32, 128)  147584      conv2d_52[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2D)  (None, 16, 16, 128)  0           conv2d_53[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_55 (Conv2D)              (None, 16, 16, 256)  295168      max_pooling2d_9[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 16, 16, 256)  1024        conv2d_55[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 16, 16, 256)  0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_56 (Conv2D)              (None, 16, 16, 256)  1048832     activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_54 (Conv2D)              (None, 16, 16, 256)  33024       max_pooling2d_9[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 16, 16, 256)  1024        conv2d_56[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 16, 16, 256)  1024        conv2d_54[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add_2 (TFOpLam (None, 16, 16, 256)  0           batch_normalization_6[0][0]      \n",
      "                                                                 batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 16, 16, 256)  0           tf.__operators__.add_2[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_57 (Conv2D)              (None, 16, 16, 256)  590080      activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_58 (Conv2D)              (None, 16, 16, 256)  590080      conv2d_57[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_6 (UpSampling2D)  (None, 32, 32, 256)  0           conv2d_58[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_59 (Conv2D)              (None, 32, 32, 128)  131200      up_sampling2d_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_6 (Concatenate)     (None, 32, 32, 256)  0           conv2d_53[0][0]                  \n",
      "                                                                 conv2d_59[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_60 (Conv2D)              (None, 32, 32, 128)  295040      concatenate_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_61 (Conv2D)              (None, 32, 32, 128)  147584      conv2d_60[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_7 (UpSampling2D)  (None, 64, 64, 128)  0           conv2d_61[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_62 (Conv2D)              (None, 64, 64, 64)   32832       up_sampling2d_7[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_7 (Concatenate)     (None, 64, 64, 128)  0           conv2d_51[0][0]                  \n",
      "                                                                 conv2d_62[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_63 (Conv2D)              (None, 64, 64, 64)   73792       concatenate_7[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_64 (Conv2D)              (None, 64, 64, 64)   36928       conv2d_63[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_65 (Conv2D)              (None, 64, 64, 1)    65          conv2d_64[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 3,537,857\n",
      "Trainable params: 3,536,321\n",
      "Non-trainable params: 1,536\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "160/160 [==============================] - 111s 685ms/step - loss: 0.4980 - accuracy: 0.7820\n",
      "Epoch 2/15\n",
      "160/160 [==============================] - 110s 685ms/step - loss: 0.3730 - accuracy: 0.8353\n",
      "Epoch 3/15\n",
      "160/160 [==============================] - 110s 685ms/step - loss: 0.3354 - accuracy: 0.8526\n",
      "Epoch 4/15\n",
      "160/160 [==============================] - 110s 687ms/step - loss: 0.3117 - accuracy: 0.8650\n",
      "Epoch 5/15\n",
      "160/160 [==============================] - 110s 689ms/step - loss: 0.3044 - accuracy: 0.8684\n",
      "Epoch 6/15\n",
      "160/160 [==============================] - 110s 689ms/step - loss: 0.2798 - accuracy: 0.8798\n",
      "Epoch 7/15\n",
      "160/160 [==============================] - 110s 689ms/step - loss: 0.2649 - accuracy: 0.8869\n",
      "Epoch 8/15\n",
      "160/160 [==============================] - 110s 690ms/step - loss: 0.2575 - accuracy: 0.8906\n",
      "Epoch 9/15\n",
      "160/160 [==============================] - 110s 689ms/step - loss: 0.2512 - accuracy: 0.8933\n",
      "Epoch 10/15\n",
      "160/160 [==============================] - 110s 689ms/step - loss: 0.2371 - accuracy: 0.9004\n",
      "Epoch 11/15\n",
      "160/160 [==============================] - 110s 689ms/step - loss: 0.2225 - accuracy: 0.9065\n",
      "Epoch 12/15\n",
      "160/160 [==============================] - 110s 689ms/step - loss: 0.2162 - accuracy: 0.9096\n",
      "Epoch 13/15\n",
      "160/160 [==============================] - 110s 689ms/step - loss: 0.2005 - accuracy: 0.9169\n",
      "Epoch 14/15\n",
      "160/160 [==============================] - 110s 689ms/step - loss: 0.1873 - accuracy: 0.9228\n",
      "Epoch 15/15\n",
      "160/160 [==============================] - 110s 690ms/step - loss: 0.1756 - accuracy: 0.9279\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a5694011f0>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_x, train_y, epochs=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 11s 554ms/step - loss: 0.2533 - accuracy: 0.8954\n",
      "Loss: 0.2533043920993805\n",
      "Accuracy: 89.54%\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(test_x, test_y)\n",
    "\n",
    "print(f\"Loss: {loss}\")\n",
    "print(f\"Accuracy: {round(accuracy*100, 2)}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('back_removal.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tfGPU",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
